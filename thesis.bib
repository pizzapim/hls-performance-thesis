
@article{nane_survey_2016,
	title = {A {Survey} and {Evaluation} of {FPGA} {High}-{Level} {Synthesis} {Tools}},
	volume = {35},
	issn = {1937-4151},
	doi = {10.1109/TCAD.2015.2513673},
	abstract = {High-level synthesis (HLS) is increasingly popular for the design of high-performance and energy-efficient heterogeneous systems, shortening time-to-market and addressing today's system complexity. HLS allows designers to work at a higher-level of abstraction by using a software program to specify the hardware functionality. Additionally, HLS is particularly interesting for designing field-programmable gate array circuits, where hardware implementations can be easily refined and replaced in the target device. Recent years have seen much activity in the HLS research community, with a plethora of HLS tool offerings, from both industry and academia. All these tools may have different input languages, perform different internal optimizations, and produce results of different quality, even for the very same input description. Hence, it is challenging to compare their performance and understand which is the best for the hardware to be implemented. We present a comprehensive analysis of recent HLS tools, as well as overview the areas of active interest in the HLS research community. We also present a first-published methodology to evaluate different HLS tools. We use our methodology to compare one commercial and three academic tools on a common set of C benchmarks, aiming at performing an in-depth evaluation in terms of performance and the use of resources.},
	number = {10},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Nane, R. and Sima, V. and Pilato, C. and Choi, J. and Fort, B. and Canis, A. and Chen, Y. T. and Hsiao, H. and Brown, S. and Ferrandi, F. and Anderson, J. and Bertels, K.},
	month = oct,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	keywords = {Bambu, comparison, Dwarv, evaluation, Field programmable gate arrays, field-programmable gate array (FPGA), Hardware, Hardware design languages, high-level synthesis (HLS), LegUp, Optimization, Program processors, survey, Yttrium},
	pages = {1591--1604},
	annote = {This paper},
	file = {IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/NGF6L7S5/7368920.html:text/html;IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/EGSGLD7S/Nane et al. - 2016 - A Survey and Evaluation of FPGA High-Level Synthes.pdf:application/pdf},
}

@article{cong_high-level_2011,
	title = {High-{Level} {Synthesis} for {FPGAs}: {From} {Prototyping} to {Deployment}},
	volume = {30},
	issn = {1937-4151},
	shorttitle = {High-{Level} {Synthesis} for {FPGAs}},
	doi = {10.1109/TCAD.2011.2110592},
	abstract = {Escalating system-on-chip design complexity is pushing the design community to raise the level of abstraction beyond register transfer level. Despite the unsuccessful adoptions of early generations of commercial high-level synthesis (HLS) systems, we believe that the tipping point for transitioning to HLS msystem-on-chip design complexityethodology is happening now, especially for field-programmable gate array (FPGA) designs. The latest generation of HLS tools has made significant progress in providing wide language coverage and robust compilation technology, platform-based modeling, advancement in core HLS algorithms, and a domain-specific approach. In this paper, we use AutoESL's AutoPilot HLS tool coupled with domain-specific system-level implementation platforms developed by Xilinx as an example to demonstrate the effectiveness of state-of-art C-to-FPGA synthesis solutions targeting multiple application domains. Complex industrial designs targeting Xilinx FPGAs are also presented as case studies, including comparison of HLS solutions versus optimized manual designs. In particular, the experiment on a sphere decoder shows that the HLS solution can achieve an 11-31\% reduction in FPGA resource usage with improved design productivity compared to hand-coded design.},
	number = {4},
	journal = {IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Cong, J. and Liu, B. and Neuendorffer, S. and Noguera, J. and Vissers, K. and Zhang, Z.},
	month = apr,
	year = {2011},
	note = {Conference Name: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	keywords = {Field programmable gate arrays, field-programmable gate array (FPGA), Hardware, high-level synthesis (HLS), Optimization, Program processors, Algorithm design and analysis, Domain-specific design, quality of results (QoR), System-on-a-chip},
	pages = {473--491},
	file = {IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/Y9DCSWDS/5737854.html:text/html;IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/5XK6KLAU/Cong et al. - 2011 - High-Level Synthesis for FPGAs From Prototyping t.pdf:application/pdf},
}

@article{paulino_optimizing_2020,
	title = {Optimizing {OpenCL} {Code} for {Performance} on {FPGA}: k-{Means} {Case} {Study} {With} {Integer} {Data} {Sets}},
	volume = {8},
	issn = {2169-3536},
	shorttitle = {Optimizing {OpenCL} {Code} for {Performance} on {FPGA}},
	doi = {10.1109/ACCESS.2020.3017552},
	abstract = {High Level Synthesis (HLS) tools targeting Field Programmable Gate Arrays (FPGAs) aim to provide a method for programming these devices via high-level abstractions. Initially, HLS support for FPGAs focused on compiling C/C++ to hardware circuits. This raised the issue of determining the programming practices which resulted in the best performing circuits. Recently, to further increase the applicability of HLS approaches, renewed effort was placed on support for HLS of OpenCL code for FPGA, raising the same issues of coding practices and performance portability. This paper explores the performance of OpenCL code compiled for FPGAs for different coding techniques. We evaluate the use of task-kernels versus NDRange kernels, data vectorization, the use of on-chip local memories, and data transfer optimizations by exploiting burst access inference. We present this exploration via a case study of the k-means algorithm, and produce a total of 10 OpenCL implementations of the kernel. To determine the effects of different data set characteristics, and to determine the gains from specialization based on number of attributes, we generated a total of 12 integer data sets. The data sets vary regarding the number of instances, number of attributes (i.e., features), and number of clusters. We also vary the number of processing cores, and present the resulting required resources and operating frequencies. Finally, we execute the same OpenCL code on a 4 GHz Intel i7-6700K CPU, showing that the FPGA achieves speedups up to \$1.54 {\textbackslash}times \$ for four cases, and energy savings up to 80\% in all cases.},
	journal = {IEEE Access},
	author = {Paulino, N. and Ferreira, J. C. and Cardoso, J. M. P.},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Field programmable gate arrays, Hardware, clustering, Encoding, FPGA, Graphics processing units, hardware accelerator, HLS, k-means, Kernel, OpenCL, Performance evaluation, Task analysis},
	pages = {152286--152304},
	file = {IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/86QVPZK7/9170625.html:text/html;IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/IXIYYMCH/Paulino et al. - 2020 - Optimizing OpenCL Code for Performance on FPGA k-.pdf:application/pdf},
}

@inproceedings{zohouri_evaluating_2016,
	address = {Salt Lake City, Utah},
	series = {{SC} '16},
	title = {Evaluating and optimizing {OpenCL} kernels for high performance computing with {FPGAs}},
	isbn = {978-1-4673-8815-3},
	abstract = {We evaluate the power and performance of the Rodinia benchmark suite using the Altera SDK for OpenCL targeting a Stratix V FPGA against a modern CPU and GPU. We study multiple OpenCL kernels per benchmark, ranging from direct ports of the original GPU implementations to loop-pipelined kernels specifically optimized for FPGAs. Based on our results, we find that even though OpenCL is functionally portable across devices, direct ports of GPU-optimized code do not perform well compared to kernels optimized with FPGA-specific techniques such as sliding windows. However, by exploiting FPGA-specific optimizations, it is possible to achieve up to 3.4x better power efficiency using an Altera Stratix V FPGA in comparison to an NVIDIA K20c GPU, and better run time and power efficiency in comparison to CPU. We also present preliminary results for Arria 10, which, due to hardened FPUs, exhibits noticeably better performance compared to Stratix V in floating-point-intensive benchmarks.},
	urldate = {2021-04-07},
	booktitle = {Proceedings of the {International} {Conference} for {High} {Performance} {Computing}, {Networking}, {Storage} and {Analysis}},
	publisher = {IEEE Press},
	author = {Zohouri, Hamid Reza and Maruyama, Naoya and Smith, Aaron and Matsuda, Motohiko and Matsuoka, Satoshi},
	month = nov,
	year = {2016},
	keywords = {FPGA, OpenCL, heterogeneous computing, performance evaluation},
	pages = {1--12},
	file = {Full Text PDF:/home/pizzapim/Zotero/storage/RGCRQRBR/Zohouri et al. - 2016 - Evaluating and optimizing OpenCL kernels for high .pdf:application/pdf},
}

@inproceedings{czajkowski_opencl_2012,
	title = {From opencl to high-performance hardware on {FPGAS}},
	doi = {10.1109/FPL.2012.6339272},
	abstract = {We present an OpenCL compilation framework to generate high-performance hardware for FPGAs. For an OpenCL application comprising a host program and a set of kernels, it compiles the host program, generates Verilog HDL for each kernel, compiles the circuit using Altera Complete Design Suite 12.0, and downloads the compiled design onto an FPGA.We can then run the application by executing the host program on a Windows(tm)-based machine, which communicates with kernels on an FPGA using a PCIe interface. We implement four applications on an Altera Stratix IV and present the throughput and area results for each application. We show that we can achieve a clock frequency in excess of 160MHz on our benchmarks, and that OpenCL computing paradigm is a viable design entry method for high-performance computing applications on FPGAs.},
	booktitle = {22nd {International} {Conference} on {Field} {Programmable} {Logic} and {Applications} ({FPL})},
	author = {Czajkowski, T. S. and Aydonat, U. and Denisenko, D. and Freeman, J. and Kinsner, M. and Neto, D. and Wong, J. and Yiannacouras, P. and Singh, D. P.},
	month = aug,
	year = {2012},
	note = {ISSN: 1946-1488},
	keywords = {Field programmable gate arrays, Hardware, Hardware design languages, Kernel, Computational modeling, Computer architecture, Instruction sets},
	pages = {531--534},
	file = {IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/V7H7NXJQ/Czajkowski et al. - 2012 - From opencl to high-performance hardware on FPGAS.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/GBC3B27Q/6339272.html:text/html},
}

@article{muslim_efficient_2017,
	title = {Efficient {FPGA} {Implementation} of {OpenCL} {High}-{Performance} {Computing} {Applications} via {High}-{Level} {Synthesis}},
	volume = {5},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2017.2671881},
	abstract = {FPGA-based accelerators have recently evolved as strong competitors to the traditional GPU-based accelerators in modern high-performance computing systems. They offer both high computational capabilities and considerably lower energy consumption. High-level synthesis (HLS) can be used to overcome the main hurdle in the mainstream usage of the FPGA-based accelerators, i.e., the complexity of their design flow. HLS enables the designers to program an FPGA directly by using high-level languages, e.g., C, C++, SystemC, and OpenCL. This paper presents an HLS-based FPGA implementation of several algorithms from a variety of application domains. A performance comparison in terms of execution time, energy, and power consumption with some high-end GPUs is performed as well. The algorithms have been modeled in OpenCL for both GPU and FPGA implementation. We conclude that FPGAs are much more energy-efficient than GPUs in all the test cases that we considered. Moreover, FPGAs can sometimes be faster than GPUs by using an FPGA-specific OpenCL programming style and utilizing a variety of appropriate HLS directives.},
	journal = {IEEE Access},
	author = {Muslim, F. B. and Ma, L. and Roozmeh, M. and Lavagno, L.},
	year = {2017},
	note = {Conference Name: IEEE Access},
	keywords = {Field programmable gate arrays, Hardware, Algorithm design and analysis, FPGA, Graphics processing units, Kernel, OpenCL, Computer architecture, GPU, High-level synthesis (HLS), low-power low-energy computations, parallel computing, Random access memory},
	pages = {2747--2762},
	file = {IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/E96C79VC/7859319.html:text/html;IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/CJSU8WWQ/Muslim et al. - 2017 - Efficient FPGA Implementation of OpenCL High-Perfo.pdf:application/pdf},
}

@inproceedings{choi_hls-based_2018,
	title = {{HLS}-{Based} {Optimization} and {Design} {Space} {Exploration} for {Applications} with {Variable} {Loop} {Bounds}},
	doi = {10.1145/3240765.3240815},
	abstract = {In order to further increase the productivity of field-programmable gate array (FPGA) programmers, several design space exploration (DSE) frameworks for high-level synthesis (HLS) tools have been recently proposed to automatically determine the FPGA design parameters. However, one of the common limitations found in these tools is that they cannot find a design point with large speedup for applications with variable loop bounds. The reason is that loops with variable loop bounds cannot be efficiently parallelized or pipelined with simple insertion of HLS directives. Also, making highly accurate prediction of cycles and resource consumption on the entire design space becomes a challenging task because of the inaccuracy of the HLS tool cycle prediction and the wide design space. In this paper we present an HLS-based FPGA optimization and DSE framework that produces a high-performance design even in the presence of variable loop bounds. We propose code transformations that increase the utilization of the compute resources for variable loops, including several computation patterns with loop-carried dependency such as floating-point reduction and prefix sum. In order to rapidly perform DSE with high accuracy, we describe a resource and cycle estimation model constructed from the information obtained from the actual HLS synthesis. Experiments on applications with variable loop bounds in Polybench benchmarks with Vivado HLS show that our framework improves the baseline implementation by 75X on average and outperforms current state-of-the-art DSE frameworks.},
	booktitle = {2018 {IEEE}/{ACM} {International} {Conference} on {Computer}-{Aided} {Design} ({ICCAD})},
	author = {Choi, Y. and Cong, J.},
	month = nov,
	year = {2018},
	note = {ISSN: 1558-2434},
	keywords = {Field programmable gate arrays, Optimization, Benchmark testing, Pipeline processing, Space exploration, Tools},
	pages = {1--8},
	file = {IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/T938KR6X/Choi and Cong - 2018 - HLS-Based Optimization and Design Space Exploratio.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/AD8AFQEK/8587738.html:text/html},
}

@inproceedings{cornu_hls_2011,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{HLS} {Tools} for {FPGA}: {Faster} {Development} with {Better} {Performance}},
	isbn = {978-3-642-19475-7},
	shorttitle = {{HLS} {Tools} for {FPGA}},
	doi = {10.1007/978-3-642-19475-7_8},
	abstract = {Designing FPGA-based accelerators is a difficult and time-consuming task which can be softened by the emergence of new generations of High Level Synthesis Tools. This paper describes how the ImpulseC C-to-hardware compiler tool has been used to develop efficient hardware for a known genomic sequence alignment algorithms and reports HLL designs performance outperforming traditional hand written optimized HDL implementations.},
	language = {en},
	booktitle = {Reconfigurable {Computing}: {Architectures}, {Tools} and {Applications}},
	publisher = {Springer},
	author = {Cornu, Alexandre and Derrien, Steven and Lavenier, Dominique},
	editor = {Koch, Andreas and Krishnamurthy, Ram and McAllister, John and Woods, Roger and El-Ghazawi, Tarek},
	year = {2011},
	keywords = {FPGA, Hardware Accelerator, High Level Synthesis Tool, ImpulseC},
	pages = {67--78},
	file = {Springer Full Text PDF:/home/pizzapim/Zotero/storage/JW5ZVPPL/Cornu et al. - 2011 - HLS Tools for FPGA Faster Development with Better.pdf:application/pdf},
}

@article{shata_optimized_2019,
	title = {Optimized implementation of {OpenCL} kernels on {FPGAs}},
	volume = {97},
	issn = {1383-7621},
	url = {https://www.sciencedirect.com/science/article/pii/S1383762118303151},
	doi = {10.1016/j.sysarc.2019.02.013},
	abstract = {Recently Field-Programmable Gate Array (FPGA) vendors, such as Altera and Xilinx released an Open Computing Language Software Development Kit (OpenCL SDK). Programming FPGAs using OpenCL can significantly reduce the development time compared to traditional low-level hardware description languages (HDLs), such as Verilog or VHDL. Nevertheless, the direct porting of OpenCL kernels to FPGA without applying the appropriate optimizations can result in significantly under-utilizing the compute capabilities of the device. In this paper, we study some optimization techniques that have not deeply discussed in the previous work despite their importance and impact on the performance of OpenCL kernels designed for FPGA. We have evaluated the impact of applying these optimizations using micro-benchmark and representative workloads. Our results show that the proposed optimizations can significantly improve the performance of OpenCL kernels by up to two order of magnitude i.e., 148.03-fold speedup over the unoptimized kernels.},
	language = {en},
	urldate = {2021-04-09},
	journal = {Journal of Systems Architecture},
	author = {Shata, Kholoud and Elteir, Marwa K. and EL-Zoghabi, Adel A.},
	month = aug,
	year = {2019},
	keywords = {FPGA, OpenCL, Atomic operations, Channels, Hardware acceleration, Optimization techniques},
	pages = {491--505},
	file = {ScienceDirect Snapshot:/home/pizzapim/Zotero/storage/GX75Y9VD/S1383762118303151.html:text/html},
}

@article{shata_optimized_2019-1,
	title = {Optimized implementation of {OpenCL} kernels on {FPGAs}},
	volume = {97},
	issn = {13837621},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1383762118303151},
	doi = {10.1016/j.sysarc.2019.02.013},
	language = {en},
	urldate = {2021-04-09},
	journal = {Journal of Systems Architecture},
	author = {Shata, Kholoud and Elteir, Marwa K. and EL-Zoghabi, Adel A.},
	month = aug,
	year = {2019},
	pages = {491--505},
}

@inproceedings{berkman_highly_1989,
	address = {New York, NY, USA},
	series = {{STOC} '89},
	title = {Highly parallelizable problems},
	isbn = {978-0-89791-307-2},
	url = {https://doi.org/10.1145/73007.73036},
	doi = {10.1145/73007.73036},
	urldate = {2021-04-09},
	booktitle = {Proceedings of the twenty-first annual {ACM} symposium on {Theory} of computing},
	publisher = {Association for Computing Machinery},
	author = {Berkman, O. and Breslauer, Dany and Galil, Zvi and Schieber, Baruch and Vishkin, Uzi},
	month = feb,
	year = {1989},
	pages = {309--319},
	file = {Full Text PDF:/home/pizzapim/Zotero/storage/FIUNN8XH/Berkman et al. - 1989 - Highly parallelizable problems.pdf:application/pdf},
}

@inproceedings{fernandez_string_2011,
	title = {String {Matching} in {Hardware} {Using} the {FM}-{Index}},
	doi = {10.1109/FCCM.2011.55},
	abstract = {String matching is a ubiquitous problem that arises in a wide range of applications in computing, e.g., packet routing, intrusion detection, web querying, and genome analysis. Due to its importance, dozens of algorithms and several data structures have been developed over the years. A recent breakthrough in this field is the FM-index, a data structure that synergistically combines the Burrows-Wheeler transform and the suffix array. In software, the FM-index allows searching (exact and approximate) in times comparable to the fastest known indices for large texts (suffix trees and suffix arrays), but has the additional advantage of being more space-efficient than those approaches. In this paper, we describe the first FPGA-based hardware implementation of the FM-index for exact pattern matching. We report experimental results on the problem of mapping short DNA sequences to a reference genome. We show that the throughput of the FM-index is significantly higher than the naive (brute force) approach. Like the Bowtie software tool, the FM-index can abandon early the hardware matching. It outperforms Bowtie by two orders of magnitude.},
	booktitle = {2011 {IEEE} 19th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines}},
	author = {Fernandez, E. and Najjar, W. and Lonardi, S.},
	month = may,
	year = {2011},
	keywords = {Field programmable gate arrays, Hardware, FPGA, Arrays, Equations, Indexes, Multiplexing, Reconfigurable Computing, String matching, Transforms},
	pages = {218--225},
	annote = {The authors show how they ported the FM-index string-searching algorithm to an FPGA. It is not clear which tool they used, but judging from the explanation of FPGA components, it could be a low-level model. They show that using the FPGA implementation can achieve 200x speedups compared to the BOWTIE mapping library.},
	file = {IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/SU7Y97XQ/Fernandez et al. - 2011 - String Matching in Hardware Using the FM-Index.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/BEUEQ7I9/5771277.html:text/html},
}

@inproceedings{ullah_implementation_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Implementation of {FM}-{Index} {Based} {Pattern} {Search} on a {Multi}-{FPGA} {System}},
	isbn = {978-3-030-44534-8},
	doi = {10.1007/978-3-030-44534-8_28},
	abstract = {Pattern matching is a versatile task which has a variety of applications including genome sequencing as a major application. During the analysis, short read mapping technique is used where short DNA sequences are mapped relative to a known reference sequence. This paper discusses the use of reconfigurable hardware to accelerate the short read mapping problem. The proposed design is based on the FM-index algorithm. Although several pattern matching techniques are available, FM-index based pattern search is perfectly suitable for genome sequencing due to the fastest mapping from known indices. In order to make use of inherent parallelism, a multi-FPGA system called Flow-in-Cloud (FiC) is used. FiC consists of multiple boards, mounting middle scale Xilinx’s FPGAs and SDRAMs, which are tightly coupled with high speed serial links. By distributing the input data transfer with I/O ring network and broadcasting I-Table, C-Table and Suffix-Array with the board-to-board interconnection network, about 10 times performance improvement was achieved when compared to the software implementation. Since the proposed method is scalable to the number of boards, we can obtain the required performance by increasing the number of boards.},
	language = {en},
	booktitle = {Applied {Reconfigurable} {Computing}. {Architectures}, {Tools}, and {Applications}},
	publisher = {Springer International Publishing},
	author = {Ullah, M. M. Imdad and Ben Ahmed, Akram and Amano, Hideharu},
	editor = {Rincón, Fernando and Barba, Jesús and So, Hayden K. H. and Diniz, Pedro and Caba, Julián},
	year = {2020},
	pages = {376--391},
	annote = {The authors ported the FM-index string-searching algorithm to an FPGA using Vivado and C++ HLS.},
	file = {Springer Full Text PDF:/home/pizzapim/Zotero/storage/9R83I3ER/Ullah et al. - 2020 - Implementation of FM-Index Based Pattern Search on.pdf:application/pdf},
}

@techreport{burrows_block-sorting_1994,
	title = {A {Block}-{Sorting} {Lossless} {Data} {Compression} {Algorithm}},
	abstract = {We describe a block-sorting, lossless data compression algorithm, and our implementation of that algorithm. We compare the performance of our implementation with widely available data compressors running on the same hardware. The algorithm works by applying a reversible transformation to a block of input text. The transformation does not itself compress the data, but re-orders it to make it easy to compress with simple algorithms such as move-to-front encoding. Our algorithm achieves speed comparable to algorithms based on the techniques of Lempel and Ziv, but optains compression close to the best statistical modelling techniques. The size of the input block must be large (a few kilobytes) to achieve good compression.},
	institution = {DIGITAL SRC RESEARCH REPORT},
	author = {Burrows, Michael and Wheeler, David},
	year = {1994},
	annote = {The paper presents the Burrows-Wheeler transformation on text to achieve efficient lossless data compression. The algorithm works by first creating all cyclic rotations of the input text. Then these rotations are sorted in lexicographical ordering to produce the Burrows-Wheeler matrix. The Burrows-Wheeler transform BWT(T) of the text T is then produced by taking the last column of the generated Burrows-Wheeler matrix. Because of the lexicographical ordering of the rotations starting from the first character, it is expected that the BWT(T) also contains runs. Because of the high probability of runs, the BWT(T) can be more easily compressed by for example run-length encoding. The paper also shows that the BWT(T) can be reversed.},
	file = {Citeseer - Full Text PDF:/home/pizzapim/Zotero/storage/XP8J45IY/Burrows and Wheeler - 1994 - A Block-Sorting Lossless Data Compression Algorith.pdf:application/pdf;Citeseer - Snapshot:/home/pizzapim/Zotero/storage/YSGA2XZ4/summary.html:text/html},
}

@misc{hoop_hits_burrows-wheeler_2014,
	title = {Burrows-{Wheeler} {Transform}},
	url = {https://www.youtube.com/watch?v=4n7NPk5lwbI},
	abstract = {Description of the BWT, how it's useful for compression, and how it can be reversed.},
	urldate = {2021-04-13},
	author = {{Hoop Hits}},
	month = sep,
	year = {2014},
}

@misc{hoop_hits_fm_2014,
	title = {{FM} {Index}},
	url = {https://www.youtube.com/watch?v=kvVGj5V65io},
	abstract = {Description of the FM Index data structure

Table of Contents:

14:40​ - Double-click to edit
17:57​ - Double-click to edit
20:26​ - Double-click to edit
25:41​ - Double-click to edit
26:51​ - Double-click to edit
28:30​ - Double-click to edit
29:37​ - Double-click to edit
33:11​ - Double-click to edit
34:00​ - Double-click to edit
36:41​ - Double-click to edit},
	urldate = {2021-04-13},
	author = {{Hoop Hits}},
	month = sep,
	year = {2014},
}

@inproceedings{ferragina_opportunistic_2000,
	title = {Opportunistic data structures with applications},
	doi = {10.1109/SFCS.2000.892127},
	abstract = {We address the issue of compressing and indexing data. We devise a data structure whose space occupancy is a function of the entropy of the underlying data set. We call the data structure opportunistic since its space occupancy is decreased when the input is compressible and this space reduction is achieved at no significant slowdown in the query performance. More precisely, its space occupancy is optimal in an information-content sense because text T[1,u] is stored using O(H/sub k/(T))+o(1) bits per input symbol in the worst case, where H/sub k/(T) is the kth order empirical entropy of T (the bound holds for any fixed k). Given an arbitrary string P[1,p], the opportunistic data structure allows to search for the occurrences of P in T in O(p+occlog/sup /spl epsiv//u) time (for any fixed /spl epsiv/{\textgreater}0). If data are uncompressible we achieve the best space bound currently known (Grossi and Vitter, 2000); on compressible data our solution improves the succinct suffix array of (Grossi and Vitter, 2000) and the classical suffix tree and suffix array data structures either in space or in query time or both. We also study our opportunistic data structure in a dynamic setting and devise a variant achieving effective search and update time bounds. Finally, we show how to plug our opportunistic data structure into the Glimpse tool (Manber and Wu, 1994). The result is an indexing tool which achieves sublinear space and sublinear query time complexity.},
	booktitle = {Proceedings 41st {Annual} {Symposium} on {Foundations} of {Computer} {Science}},
	author = {Ferragina, P. and Manzini, G.},
	month = nov,
	year = {2000},
	note = {ISSN: 0272-5428},
	keywords = {Computer science, Costs, Data engineering, Data structures, Entropy, Fault tolerance, Indexing, Plugs, Postal services, Tree data structures},
	pages = {390--398},
	annote = {The paper presents a novel data indexing algorithm with a great space occupancy and run-time trade-off. The algorithm makes use of several pre-generated data structures for efficient searching. The first is the Burrows-Wheeler transform (BWT) of the input string. Secondly, an "LF-map", which exploits the Last-First relation of the BWT to find the characters following the ones in the BWT. This data structures effectively allows for pattern matching. The third data structure is the small C array, which holds accumulated counts for each character in the alphabet. The last data structure allows to find the actual indices of the requested patterns inside the original text using a suffix array. Even though using the BWT and the other data structures is already space efficient, there is a trade-off between space occupancy and run-time performance to be made. It is shown that we can precalculate only some entries in the LF-map and the suffix array, and postpone the relatively small amount of computation until run-time. This can speed up the algorithm as RAM access is generally more expensive.},
	file = {IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/VK6LN6R7/Ferragina and Manzini - 2000 - Opportunistic data structures with applications.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pizzapim/Zotero/storage/492U3V9J/892127.html:text/html},
}

@misc{petri_mpetrifm-index_2021,
	title = {mpetri/{FM}-{Index}},
	copyright = {GPL-3.0 License         ,                 GPL-3.0 License},
	url = {https://github.com/mpetri/FM-Index},
	abstract = {FM-Index full-text index implementation using RRR Wavelet trees (libcds) and fast suffix sorting (libdivsufsort) including experimental results.},
	urldate = {2021-04-13},
	author = {Petri, Matthias},
	month = mar,
	year = {2021},
	note = {original-date: 2011-03-19T02:16:18Z},
}

@inproceedings{beller_space-efficient_2013,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Space-{Efficient} {Construction} of the {Burrows}-{Wheeler} {Transform}},
	isbn = {978-3-319-02432-5},
	doi = {10.1007/978-3-319-02432-5_5},
	abstract = {The Burrows-Wheeler transform (BWT), originally invented for data compression, is nowadays also the core of many self-indexes, which can be used to solve many problems in bioinformatics. However, the memory requirement during the construction of the BWT is often the bottleneck in applications in the bioinformatics domain.In this paper, we present a linear-time semi-external algorithm whose memory requirement is only about one byte per input symbol. Our experiments show that this algorithm provides a new time-memory trade-off between external and in-memory construction algorithms.},
	language = {en},
	booktitle = {String {Processing} and {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Beller, Timo and Zwerger, Maike and Gog, Simon and Ohlebusch, Enno},
	editor = {Kurland, Oren and Lewenstein, Moshe and Porat, Ely},
	year = {2013},
	keywords = {Alphabet Size, Data Compression, External Memory, Input String, Random Access},
	pages = {5--16},
	file = {Springer Full Text PDF:/home/pizzapim/Zotero/storage/KW2SUTVE/Beller et al. - 2013 - Space-Efficient Construction of the Burrows-Wheele.pdf:application/pdf},
}

@misc{noauthor_learning_nodate,
	title = {Learning {Resources}: {Compact} {Data} {Structures} - {FM}-{Index}},
	url = {https://docs.seqan.de/seqan/learning-resources/fm_index.html},
	urldate = {2021-04-14},
	file = {Learning Resources\: Compact Data Structures - FM-Index:/home/pizzapim/Zotero/storage/LCI69BVA/fm_index.html:text/html},
}

@article{langmead_introduction_nodate,
	title = {Introduction to the {Burrows}-{Wheeler} {Transform} and {FM} {Index}},
	language = {en},
	author = {Langmead, Ben},
	pages = {12},
	file = {Langmead - Introduction to the Burrows-Wheeler Transform and .pdf:/home/pizzapim/Zotero/storage/VGRJ2S8U/Langmead - Introduction to the Burrows-Wheeler Transform and .pdf:application/pdf},
}

@article{langmead_ultrafast_2009,
	title = {Ultrafast and memory-efficient alignment of short {DNA} sequences to the human genome},
	volume = {10},
	copyright = {2009 Langmead et al.; licensee BioMed Central Ltd.},
	issn = {1474-760X},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/gb-2009-10-3-r25},
	doi = {10.1186/gb-2009-10-3-r25},
	abstract = {Bowtie is an ultrafast, memory-efficient alignment program for aligning short DNA sequence reads to large genomes. For the human genome, Burrows-Wheeler indexing allows Bowtie to align more than 25 million reads per CPU hour with a memory footprint of approximately 1.3 gigabytes. Bowtie extends previous Burrows-Wheeler techniques with a novel quality-aware backtracking algorithm that permits mismatches. Multiple processor cores can be used simultaneously to achieve even greater alignment speeds. Bowtie is open source http://bowtie.cbcb.umd.edu .},
	language = {en},
	number = {3},
	urldate = {2021-04-18},
	journal = {Genome Biology},
	author = {Langmead, Ben and Trapnell, Cole and Pop, Mihai and Salzberg, Steven L.},
	month = mar,
	year = {2009},
	note = {Number: 3
Publisher: BioMed Central},
	pages = {1--10},
	file = {Full Text PDF:/home/pizzapim/Zotero/storage/QXT64Y92/Langmead et al. - 2009 - Ultrafast and memory-efficient alignment of short .pdf:application/pdf;Snapshot:/home/pizzapim/Zotero/storage/PTXASKNP/gb-2009-10-3-r25.html:text/html},
}

@inproceedings{ferragina_alphabet-friendly_2004,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {An {Alphabet}-{Friendly} {FM}-{Index}},
	isbn = {978-3-540-30213-1},
	doi = {10.1007/978-3-540-30213-1_23},
	abstract = {We show that, by combining an existing compression boosting technique with the wavelet tree data structure, we are able to design a variant of the FM-index which scales well with the size of the input alphabet Σ. The size of the new index built on a string T[1,n] is bounded by {\textbackslash}(n H\_\{k\}(T) + O{\textbackslash}bigl((n {\textbackslash}log{\textbackslash}log n)/{\textbackslash}log\_\{{\textbackslash}vert \{{\textbackslash}Sigma\}{\textbackslash}vert \} n{\textbackslash}bigr){\textbackslash}) bits, where H k (T) is the k-th order empirical entropy of T.The above bound holds simultaneously for all k≤αlog ∣ Σ ∣ n and 0{\textless} α {\textless} 1. Moreover, the index design does not depend on the parameter k, which plays a role only in analysis of the space occupancy.Using our index, the counting of the occurrences of an arbitrary pattern P[1,p] as a substring of T takes O(p log ∣ Σ ∣ ) time. Locating each pattern occurrence takes O(log ∣ Σ ∣ (log2n/loglog n)) time. Reporting a text substring of length ℓ takes O((ℓ + log2 n/loglog n) log ∣ Σ∣ ) time.},
	language = {en},
	booktitle = {String {Processing} and {Information} {Retrieval}},
	publisher = {Springer},
	author = {Ferragina, Paolo and Manzini, Giovanni and Mäkinen, Veli and Navarro, Gonzalo},
	editor = {Apostolico, Alberto and Melucci, Massimo},
	year = {2004},
	keywords = {Alphabet Size, Compression Algorithm, Discrete Algorithm, Pattern Occurrence, Query Time},
	pages = {150--160},
	file = {Springer Full Text PDF:/home/pizzapim/Zotero/storage/2AILW93G/Ferragina et al. - 2004 - An Alphabet-Friendly FM-Index.pdf:application/pdf},
}

@inproceedings{zhang_parallelization_2008,
	title = {Parallelization of {FM}-{Index}},
	doi = {10.1109/HPCC.2008.165},
	abstract = {A parallel design and implementation of FM-index is presented in this paper. In applications, the performance of the FM-index is crucial, which is a self-contained, highly compressed indexing algorithm. With the popularity of multi-core processors, parallel computing allows the FM-index to run faster by performing multiple computations simultaneously when possible. Our approach works by splitting input data into overlapping blocks with equal size, and running them through the FM-index algorithm simultaneously on multiple processors. After analyzing and refactoring the sequential version, we organize the data flows of all operations according to a unified parallel framework. The experimental results show that, in general our approach has achieved a significant and sub-linear speedup on widespread symmetrical multi-processing architectures. This will greatly reduce the running time of executing operations on large data sets.},
	booktitle = {2008 10th {IEEE} {International} {Conference} on {High} {Performance} {Computing} and {Communications}},
	author = {Zhang, D. and Zhang, Y. and Liu, S. and Huang, X.},
	month = sep,
	year = {2008},
	keywords = {Program processors, Arrays, Indexes, Indexing, Block processing, Clocks, Construction industry, FM-index, Multi-core, Parallel computing, Parallel processing, Self-index},
	pages = {169--173},
	file = {IEEE Xplore Full Text PDF:/home/pizzapim/Zotero/storage/VJX9QI7C/Zhang et al. - 2008 - Parallelization of FM-Index.pdf:application/pdf},
}

@article{makinen_compressed_2007,
	title = {Compressed full-text indexes},
	volume = {39},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/1216370.1216372},
	doi = {10.1145/1216370.1216372},
	abstract = {Full-text indexes provide fast substring search over large text collections. A serious problem of these indexes has traditionally been their space consumption. A recent trend is to develop indexes that exploit the compressibility of the text, so that their size is a function of the compressed text length. This concept has evolved into self-indexes, which in addition contain enough information to reproduce any text portion, so they replace the text. The exciting possibility of an index that takes space close to that of the compressed text, replaces it, and in addition provides fast search over it, has triggered a wealth of activity and produced surprising results in a very short time, which radically changed the status of this area in less than 5 years. The most successful indexes nowadays are able to obtain almost optimal space and search time simultaneously. In this article we present the main concepts underlying (compressed) self-indexes. We explain the relationship between text entropy and regularities that show up in index structures and permit compressing them. Then we cover the most relevant self-indexes, focusing on how they exploit text compressibility to achieve compact structures that can efficiently solve various search problems. Our aim is to give the background to understand and follow the developments in this area.},
	number = {1},
	urldate = {2021-04-19},
	journal = {ACM Computing Surveys},
	author = {Mäkinen, Veli and Navarro, Gonzalo},
	month = apr,
	year = {2007},
	keywords = {entropy, text compression, Text indexing},
	pages = {2--es},
	file = {Full Text PDF:/home/pizzapim/Zotero/storage/6YU8EPIH/Navarro and Mäkinen - 2007 - Compressed full-text indexes.pdf:application/pdf},
}

@article{langmead_burrows-wheeler_1994,
	title = {Burrows-{Wheeler} {Transform} and {FM} {Index}},
	language = {en},
	journal = {Technical Report},
	author = {Langmead, Ben},
	year = {1994},
	pages = {41},
	file = {Langmead - 1994 - Burrows-Wheeler Transform and FM Index.pdf:/home/pizzapim/Zotero/storage/MRXREYT8/Langmead - 1994 - Burrows-Wheeler Transform and FM Index.pdf:application/pdf},
}

@misc{ferragina_pizzachili_nodate,
	title = {Pizza\&{Chili} {Corpus} -- {Compressed} {Indexes} and their {Testbeds}},
	url = {http://pizzachili.dcc.uchile.cl/index.html},
	urldate = {2021-04-21},
	author = {Ferragina, Paolo and Navarro, Gonzalo},
	file = {Pizza&Chili Corpus -- Compressed Indexes and their Testbeds:/home/pizzapim/Zotero/storage/IAAF94ZQ/texts.html:text/html},
}
